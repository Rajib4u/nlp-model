{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "hL1QVJuk_Gr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense,Flatten,LSTM,Dropout,Embedding\n",
        "from tensorflow.keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "PM6MtJ07_PG7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/torrensteam/nlp-model.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh5_HBfa_W-H",
        "outputId": "9390039d-eca2-493d-8845-4018ba113b0f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp-model'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 25 (delta 1), reused 22 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), 29.21 MiB | 6.11 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract review text and save as csv files"
      ],
      "metadata": {
        "id": "6Qwx00UM5piG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('/content/nlp-model/sorted_data_acl/books/positive.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('book_positive.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ],
      "metadata": {
        "id": "0ULWPFKh_eN2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/nlp-model/sorted_data_acl/books/negative.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('book_negative.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ],
      "metadata": {
        "id": "GhD-ETOr_s0h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/nlp-model/sorted_data_acl/dvd/positive.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('dvd_positive.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ],
      "metadata": {
        "id": "BQ9qdtP4_5Z5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/nlp-model/sorted_data_acl/dvd/negative.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('dvd_negative.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ],
      "metadata": {
        "id": "2N4ehspWAB5v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/nlp-model/sorted_data_acl/electronics/positive.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('electronics_positive.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ],
      "metadata": {
        "id": "sY_ZaDXMAI3M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/nlp-model/sorted_data_acl/electronics/negative.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('electronics_negative.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ],
      "metadata": {
        "id": "yMQRuC4KALtk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/nlp-model/sorted_data_acl/kitchen_&_housewares/positive.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('kitchen_positive.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ],
      "metadata": {
        "id": "ORZUuOtiAS6A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/nlp-model/sorted_data_acl/kitchen_&_housewares/negative.review', 'r') as file:\n",
        "    content = file.read()\n",
        "    start_tag = '<review_text>'\n",
        "    end_tag = '</review_text>'\n",
        "    csv_file = open('kitchen_negative.csv', 'w', newline='', encoding='utf-8')\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(['Review Text'])\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        start_index = content.find(start_tag, start_index)\n",
        "        if start_index == -1:\n",
        "            break\n",
        "        start_index += len(start_tag)\n",
        "        end_index = content.find(end_tag, start_index)\n",
        "        review_text = content[start_index:end_index].strip()\n",
        "        csv_writer.writerow([review_text])\n",
        "    csv_file.close()"
      ],
      "metadata": {
        "id": "QM1NMgusAUl9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_p = pd.read_csv(\"/content/book_positive.csv\")\n",
        "book_n = pd.read_csv(\"/content/book_negative.csv\")\n",
        "dvd_p  = pd.read_csv(\"/content/dvd_positive.csv\")\n",
        "dvd_n  = pd.read_csv(\"/content/dvd_negative.csv\")\n",
        "ele_p  = pd.read_csv(\"/content/electronics_positive.csv\")\n",
        "ele_n  = pd.read_csv(\"/content/electronics_negative.csv\")\n",
        "kit_p  = pd.read_csv(\"/content/kitchen_positive.csv\")\n",
        "kit_n  = pd.read_csv(\"/content/kitchen_negative.csv\")"
      ],
      "metadata": {
        "id": "_46HSJQQAdPT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Concatenation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FLfwJX3M-FqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5OJ0NhMtddoN"
      },
      "outputs": [],
      "source": [
        "positive = pd.concat([book_p,dvd_p,ele_p,kit_p],axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SwSSUGQFev5P"
      },
      "outputs": [],
      "source": [
        "positive[\"Label\"] = [1]*len(positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OJG_uhzVdz0K"
      },
      "outputs": [],
      "source": [
        "negative = pd.concat([book_n,dvd_n,ele_n,kit_n],axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "m98Fg8iDff59"
      },
      "outputs": [],
      "source": [
        "negative[\"Label\"] = [0]*len(negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jWPC6kVvgVfb"
      },
      "outputs": [],
      "source": [
        "review_dataset = pd.concat([positive,negative],axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "d5rv2-DAk3kn"
      },
      "outputs": [],
      "source": [
        "review_dataset = review_dataset.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sp_IvzjXlDW3"
      },
      "outputs": [],
      "source": [
        "review_dataset.to_pickle(\"combined_review.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eI3SR7GDmJLK"
      },
      "outputs": [],
      "source": [
        "review = pd.read_pickle(\"/content/combined_review.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WQtBHQAknyD4"
      },
      "outputs": [],
      "source": [
        "X = review[\"Review Text\"]\n",
        "y = review[\"Label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wzSLxCw9oOvS"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,stratify = y,random_state = 42 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization & Training Model"
      ],
      "metadata": {
        "id": "MFzg4HQV-kjc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NqEActnNfvKL"
      },
      "outputs": [],
      "source": [
        "token = Tokenizer(num_words = 1000)\n",
        "token.fit_on_texts(x_train)\n",
        "sequences_train = token.texts_to_sequences(x_train)\n",
        "sequs_matrics_train = pad_sequences(sequences_train,maxlen = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "o4A4UpTggElT"
      },
      "outputs": [],
      "source": [
        "sequences_test = token.texts_to_sequences(x_test)\n",
        "sequs_matrics_test = pad_sequences(sequences_test,maxlen = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zJep2Fmh3Uc5"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape = [1000]),\n",
        "    keras.layers.Embedding(1000,50),\n",
        "    keras.layers.LSTM(64),\n",
        "    keras.layers.Dense(50,activation = \"relu\"),\n",
        "    keras.layers.Dense(1,activation = \"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fMPBF6VJ3XkY"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = \"rmsprop\",\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19Bl6CnZouWd",
        "outputId": "b1d21104-b113-44db-ceb0-ae8e7761d110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - 132s 648ms/step - loss: 0.6234 - accuracy: 0.6431 - val_loss: 0.5495 - val_accuracy: 0.7206\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - 130s 651ms/step - loss: 0.4748 - accuracy: 0.7833 - val_loss: 0.4972 - val_accuracy: 0.7681\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - 132s 661ms/step - loss: 0.4186 - accuracy: 0.8205 - val_loss: 0.5018 - val_accuracy: 0.7619\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - 132s 660ms/step - loss: 0.4044 - accuracy: 0.8250 - val_loss: 0.4932 - val_accuracy: 0.7681\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - 131s 657ms/step - loss: 0.3735 - accuracy: 0.8419 - val_loss: 0.4708 - val_accuracy: 0.7937\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76c1f9a590>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.fit(sequs_matrics_train,y_train,epochs = 5,validation_data = (sequs_matrics_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model as pickle file"
      ],
      "metadata": {
        "id": "Zgixcix58dxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "PA6BFvlnqT_e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = \"model.pkl\"\n",
        "with open(model_file,\"wb\") as f:\n",
        "  pickle.dump(model,f)"
      ],
      "metadata": {
        "id": "4Av3wT5eqV1w"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_file = \"token.pkl\"\n",
        "with open(tokenizer_file,\"wb\") as file:\n",
        "  pickle.dump(token,file)"
      ],
      "metadata": {
        "id": "2pIi2s2BYukl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/model.h5\")"
      ],
      "metadata": {
        "id": "WbAGID5toq-l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_vector(text,token):\n",
        "  sequences_test = token.texts_to_sequences([text])\n",
        "  sequs_matrics_test = pad_sequences(sequences_test,maxlen = 1000)\n",
        "  return sequs_matrics_test "
      ],
      "metadata": {
        "id": "b_6c9iNFvoxA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Sphere by Michael Crichton is an excellant novel. This was certainly the hardest to put down of all of the Crichton novels that I have read. \\n\\nThe story revolves around a man named Norman Johnson. Johnson is a phycologist. He travels with 4 other civilans to a remote location in the Pacific Ocean to help the Navy in a top secret misssion. They quickly learn that under the ocean is a half mile long spaceship. The civilans travel to a center 1000 feet under the ocean to live while researching the spacecraft. They are joined by 5 Navy personel to help them run operations. However on the surface a typhoon comes and the support ships on the surface must leave. The team of ten is stuck 1000 feet under the surface of the ocean. After a day under the sea they find out that the spacecraft is actually an American ship that has explored black holes and has brought back some strange things back to earth.\\n\\nThis novel does not have the research that some of the other Crichton novels have, but it still has a lot of information on random things from the lawes of partial pressure to behavior analysis.\\n\\nI would strongly recommend this book\""
      ],
      "metadata": {
        "id": "nxfehEqUxeLY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class = \"positive\" if model.predict(text_to_vector(text,token))>0.5 else \"negative\""
      ],
      "metadata": {
        "id": "2l5hEUNo0SzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8cea9e-a468-43c4-c809-8198f84f8044"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 505ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L9Yz_boXwDgq",
        "outputId": "4b940973-3546-493b-a2d3-fcbe60a9ff0a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*UI* Interface\n"
      ],
      "metadata": {
        "id": "giYf9vHCwSnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter your text: \")\n",
        "def text_to_vector(text,token):\n",
        "  sequences_test = token.texts_to_sequences([text])\n",
        "  sequs_matrics_test = pad_sequences(sequences_test,maxlen = 1000)\n",
        "  return sequs_matrics_test\n",
        "\n",
        "predicted_class = \"positive\" if model.predict(text_to_vector(text,token))>0.5 else \"negative\"\n",
        "print(\"This review sentence is:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zlWpywBwWi-",
        "outputId": "509fc8f8-179a-455d-e2d9-8f33d46c3653"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text: Dr. Oz is an accomplished heart surgeon in the field of cardiac transplantation.\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "This review sentence is: positive\n"
          ]
        }
      ]
    }
  ]
}